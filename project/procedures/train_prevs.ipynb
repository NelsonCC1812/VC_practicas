{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (img_normalizer.py, line 36)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\practicas01\\AppData\\Local\\miniconda3\\envs\\vc\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 10\u001b[1;36m\n\u001b[1;33m    import modules.img_normalizer\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\practicas01\\Desktop\\tmp\\VC_practicas\\project\\procedures\\..\\modules\\img_normalizer.py:36\u001b[1;36m\u001b[0m\n\u001b[1;33m    return cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_RGB2BGR) img, cv2.COLOR_BGR2GRAY)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---\n",
    "import sys; sys.path.append('../')\n",
    "from commons.dataset import *\n",
    "import modules.img_normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INPUT = DATASETS_PATHS.faces\n",
    "DATASET_OUTPUT = DATASETS_PATHS.norm_faces\n",
    "\n",
    "IMAGE_SIZE = 220\n",
    "\n",
    "TRAIN_PERCENT = .65# .7\n",
    "VAL_PERCENT = .2\n",
    "TEST_PERCENT = .15# .1\n",
    "RANDOM_STATE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_INPUT.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset AnÃ¡lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean & std\n",
    "\n",
    "sum_intensity = 0.0\n",
    "sum_squared_intensity = 0.0\n",
    "n_samples = 0\n",
    "\n",
    "def process(path):\n",
    "    cv2.imread(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for idx,path in enumerate(dataset.path.sample(3).iloc):\n",
    "    plt.subplot(1,3,idx+1)\n",
    "    plt.imshow(normalizer(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_faces_dataset = pd.DataFrame(columns=dataset.columns)\n",
    "\n",
    "count = 0\n",
    "def process(entry):\n",
    "    cv2.imwrite(os.path.join(DATASET_OUTPUT.data, f'{count:3}.png'),\n",
    "        cv2.cvtColor(normalizer(\n",
    "            cv2.cvtColor(cv2.imread(entry.path), cv2.COLOR_BGR2RGB)), cv2.COLOR_RGB2BGR))\n",
    "    count+=1\n",
    "\n",
    "dataset.apply(process, axis=1)\n",
    "norm_faces_dataset.to_csv(DATASET_OUTPUT.info, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data slicing in training, validation and tests groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tsetid\tmin-max\tproportion\n",
      "> train: \t287  \t9-10 \t0.65977\n",
      "> val: \t\t87  \t3-3 \t0.20000\n",
      "> test: \t61  \t2-3 \t0.14023\n"
     ]
    }
   ],
   "source": [
    "train_dataset, tmp = train_test_split(dataset, train_size=TRAIN_PERCENT, stratify=dataset.setid, shuffle=True, random_state=RANDOM_STATE)\n",
    "val_dataset, test_dataset = train_test_split(tmp, test_size=TEST_PERCENT/(TEST_PERCENT+VAL_PERCENT), stratify=tmp.setid, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print('\\t\\tsetid\\tmin-max\\tproportion')\n",
    "print(f\"> train: \\t{train_dataset.count(axis=1).size}  \\t{train_dataset.setid.value_counts().min()}-{train_dataset.setid.value_counts().max()} \\t{train_dataset.count(axis=1).size/dataset.count(axis=1).size:.5f}\")\n",
    "print(f\"> val: \\t\\t{val_dataset.count(axis=1).size}  \\t{val_dataset.setid.value_counts().min()}-{val_dataset.setid.value_counts().max()} \\t{val_dataset.count(axis=1).size/dataset.count(axis=1).size:.5f}\")\n",
    "print(f\"> test: \\t{test_dataset.count(axis=1).size}  \\t{test_dataset.setid.value_counts().min()}-{test_dataset.setid.value_counts().max()} \\t{test_dataset.count(axis=1).size/dataset.count(axis=1).size:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path\n",
      "False    287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "path\n",
      "False    287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "path\n",
      "False    87\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((train_dataset.path.isin(test_dataset.path) == True).value_counts(), end='\\n\\n')\n",
    "print((train_dataset.path.isin(val_dataset.path) == True).value_counts(), end='\\n\\n')\n",
    "print((val_dataset.path.isin(test_dataset.path) == True).value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save / load datasets slices (train, val, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'train_dataset.csv'), index=False)\n",
    "val_dataset.to_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'val_dataset.csv'), index=False)\n",
    "test_dataset.to_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'test_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'train_dataset.csv'))\n",
    "val_dataset = pd.read_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'val_dataset.csv'))\n",
    "test_dataset = pd.read_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'test_dataset.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
