{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# ---\n",
    "import sys; sys.path.append('../')\n",
    "\n",
    "from commons.imgs_mean_std import *\n",
    "\n",
    "from commons.dataset import *\n",
    "from commons.imageutils import *\n",
    "from commons.HistCollection import *\n",
    "\n",
    "from modules.img_transforms import *\n",
    "from modules.train_functions import *\n",
    "from modules.Comparator import *\n",
    "\n",
    "from modules.Dataset import *\n",
    "from modules.EarlyStopper import *\n",
    "\n",
    "from modules.Model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants & hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=None\n",
    "\n",
    "IMAGE_SIZE=220\n",
    "\n",
    "BATCH_SIZE=32\n",
    "NUM_EPOCHS=100\n",
    "\n",
    "LEARNING_RATE=.0001\n",
    "MOMENTUM=.9\n",
    "\n",
    "EARLY_PATIENCE=15\n",
    "SCHEDULER_PATIENCE=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(torch.cuda.is_available())\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Devices:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'train_dataset.csv'))\n",
    "val_dataset = pd.read_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'val_dataset.csv'))\n",
    "test_dataset = pd.read_csv(os.path.join(DATASETS_PATHS.norm_faces.info, 'test_dataset.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization= normalize(IMAGE_SIZE, MEAN, STD)\n",
    "\n",
    "train_dataset = CD_TrippletsCreator(train_dataset, transform=normalization, data_augmentation_tranforms=[data_augmentation()])\n",
    "val_dataset = CD_TrippletsCreator(val_dataset, transform=normalization)\n",
    "test_dataset = CD_TrippletsCreator(test_dataset, transform=normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_callback(**kwarks):\n",
    "    print(\" > Early Stop <\")\n",
    "\n",
    "early_stopper = EarlyStopper(EARLY_PATIENCE, .001, callback=early_callback, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.TripletMarginWithDistanceLoss(distance_function=dst).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.2, patience=SCHEDULER_PATIENCE, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(**kwargs):\n",
    "\tprint(f\"Epoch: {kwargs['epoch']} =================================\")\n",
    "\tprint(f\"\\ttrain_loss: {kwargs['train_loss']:2f}\\tval_loss: {kwargs['val_loss']:2f}\")\n",
    "\tprint(f\"\\tdst_mean_train (pos, neg): ({np.mean(kwargs['train_h'].posit_dst[-1]):2f}, {np.mean(kwargs['train_h'].negat_dst[-1]):2f}) dst_mean_val (pos, neg): ({np.mean(kwargs['val_h'].posit_dst[-1]):2f}, {np.mean(kwargs['val_h'].negat_dst[-1]):2f})\")\n",
    "\n",
    "\n",
    "train_h, val_h = train_loop(model, train_loader, val_loader=val_loader,\n",
    "                            optimizer=optimizer, criterion=criterion, dst=dst, num_epoch=100, device=device,\n",
    "                            early_stopper=early_stopper, scheduler=scheduler, callback=callback)\n",
    "\n",
    "model.load_state_dict(early_stopper.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'model.pth', complete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_analisys(**kwargs):\n",
    "\n",
    "\ttrain_posit_mean_h = [np.mean(elm) for elm in  kwargs['train_h'].posit_dst]\n",
    "\ttrain_negat_mean_h = [np.mean(elm) for elm in  kwargs['train_h'].negat_dst]\n",
    "\n",
    "\ttrain_posit_median_h = [np.median(elm) for elm in kwargs['train_h'].posit_dst]\n",
    "\ttrain_negat_median_h = [np.median(elm) for elm in kwargs['train_h'].negat_dst]\n",
    "\n",
    "\tval_posit_mean_h = [np.mean(elm) for elm in  kwargs['val_h'].posit_dst]\n",
    "\tval_negat_mean_h = [np.mean(elm) for elm in  kwargs['val_h'].negat_dst]\n",
    "\n",
    "\tval_posit_median_h = [np.median(elm) for elm in kwargs['val_h'].posit_dst]\n",
    "\tval_negat_median_h = [np.median(elm) for elm in kwargs['val_h'].negat_dst]\n",
    "\n",
    "\n",
    "\tplt.figure(figsize=(24, 6))\n",
    "\n",
    "\tplt.subplot(1, 3, 1); plt.title('Train / Val loss')\n",
    "\tplt.xlabel('Epochs')\n",
    "\tplt.ylabel('Loss')\n",
    "\tplt.xticks([1, len(kwargs['val_h'])])\n",
    "\tplt.plot(kwargs['train_h'].loss, label='Train')\n",
    "\tplt.plot(kwargs['val_h'].loss, label='Val')\n",
    "\tplt.plot(kwargs['best_loss'][0], kwargs['best_loss'][1], 'o', )\n",
    "\tplt.annotate('best', (kwargs['best_loss'][0], kwargs['best_loss'][1]))\n",
    "\tplt.axvline(kwargs['best_loss'][0], linestyle='dashed', color='red', linewidth=1)\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.subplot(1, 3, 2); plt.title('Distances means')\n",
    "\tplt.xlabel('Epochs')\n",
    "\tplt.ylabel('Mean')\n",
    "\tplt.xticks([1, len(kwargs['val_h'])])\n",
    "\tplt.plot(train_posit_mean_h, label='Train positive')\n",
    "\tplt.plot(train_negat_mean_h, label='Train negative')\n",
    "\tplt.plot(val_posit_mean_h, label='Val positive')\n",
    "\tplt.plot(val_negat_mean_h, label='Val negative')\n",
    "\tplt.axvline(kwargs['best_loss'][0], linestyle='dashed', color='red', linewidth=1)\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.subplot(1,3,3); plt.title('Distances medians')\n",
    "\tplt.xlabel('Epoch')\n",
    "\tplt.ylabel('Median')\n",
    "\tplt.xticks([1, len(kwargs['val_h'])])\n",
    "\tplt.plot(train_posit_median_h, label='Train positive')\n",
    "\tplt.plot(train_negat_median_h, label='Train negative')\n",
    "\tplt.plot(val_posit_median_h, label='Val positive')\n",
    "\tplt.plot(val_negat_median_h, label='Val negative')\n",
    "\tplt.axvline(kwargs['best_loss'][0], linestyle='dashed', color='red', linewidth=1)\n",
    "\tplt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_analisys(train_h=train_h, val_h=val_h, best_loss=(early_stopper.best_epoch, early_stopper.best_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_h = eval(model, test_loader, device=device, criterion=criterion, dst=dst)\n",
    "print('Loss', test_h.loss)\n",
    "print(f'Posit dst:\\t| mean {np.mean(test_h.posit_dst)}\\t| median {np.median(test_h.posit_dst)}\\t| std {np.std(test_h.posit_dst)}\\t| min, max {np.min(test_h.posit_dst)}, {np.max(test_h.posit_dst)}\\t| diff(min,max) {np.max(test_h.posit_dst)-np.min(test_h.posit_dst)}')\n",
    "print(f'Negat dst:\\t| mean {np.mean(test_h.negat_dst)}\\t| median {np.median(test_h.negat_dst)}\\t| std {np.std(test_h.negat_dst)}\\t| min, max {np.min(test_h.negat_dst)}, {np.max(test_h.negat_dst)}\\t| diff(min,max) {np.max(test_h.negat_dst)-np.min(test_h.negat_dst)}')\n",
    "print(f'Diff(max(posit_dst), min(negat_dst)) {min(test_h.negat_dst) - max(test_h.posit_dst)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segundo entrenamiento con el mejor modelo actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h_, val_h_ =  train_h.copy(), val_h.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper.reset()\n",
    "\n",
    "train_h_, val_h_ = train_loop(model, train_loader, val_loader=val_loader, initial_epoch=early_stopper.best_epoch,\n",
    "                            optimizer=optimizer, criterion=criterion, dst=dst, num_epoch=100, device=device,\n",
    "                            early_stopper=early_stopper, scheduler=scheduler, callback=callback, train_h=train_h_, val_h=val_h_)\n",
    "\n",
    "model.load_state_dict(early_stopper.best_model)\n",
    "save_model(model, 'model.pth', complete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(early_stopper.best_model)\n",
    "save_model(model, 'model.pth', complete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisys again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_analisys(train_h=train_h_, val_h=val_h_, best_loss=(early_stopper.best_epoch, early_stopper.best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_h = eval(model, test_loader, device=device, criterion=criterion, dst=dst)\n",
    "print('Loss', test_h.loss)\n",
    "print(f'Posit dst:\\t| mean {np.mean(test_h.posit_dst)}\\t| median {np.median(test_h.posit_dst)}\\t| std {np.std(test_h.posit_dst)}\\t| min, max {np.min(test_h.posit_dst)}, {np.max(test_h.posit_dst)}\\t| diff(min,max) {np.max(test_h.posit_dst)-np.min(test_h.posit_dst)}')\n",
    "print(f'Negat dst:\\t| mean {np.mean(test_h.negat_dst)}\\t| median {np.median(test_h.negat_dst)}\\t| std {np.std(test_h.negat_dst)}\\t| min, max {np.min(test_h.negat_dst)}, {np.max(test_h.negat_dst)}\\t| diff(min,max) {np.max(test_h.negat_dst)-np.min(test_h.negat_dst)}')\n",
    "print(f'Diff(max(posit_dst), min(negat_dst)) {min(test_h.negat_dst) - max(test_h.posit_dst)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIENES UN PROBLEMA EN COMO HACES EL SEGUNDO ENTRENAMIENTO, PORQUE SI EMPIEZAS DESDE LA EPOCA 14, Y TIENES EL REGISTRO ANTERIOR (VAL_H), NO CUADRAN LAS COSAS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
