{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data slicing in training, validation and tests groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tsetid\tmin-max\tproportion\n",
      "> train: \t287  \t9-10 \t0.65977\n",
      "> val: \t\t87  \t3-3 \t0.20000\n",
      "> test: \t61  \t2-3 \t0.14023\n"
     ]
    }
   ],
   "source": [
    "train_dataset, tmp = train_test_split(dataset, train_size=TRAIN_PERCENT, stratify=dataset.setid, shuffle=True, random_state=RANDOM_STATE)\n",
    "val_dataset, test_dataset = train_test_split(tmp, test_size=TEST_PERCENT/(TEST_PERCENT+VAL_PERCENT), stratify=tmp.setid, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print('\\t\\tsetid\\tmin-max\\tproportion')\n",
    "print(f\"> train: \\t{train_dataset.count(axis=1).size}  \\t{train_dataset.setid.value_counts().min()}-{train_dataset.setid.value_counts().max()} \\t{train_dataset.count(axis=1).size/dataset.count(axis=1).size:.5f}\")\n",
    "print(f\"> val: \\t\\t{val_dataset.count(axis=1).size}  \\t{val_dataset.setid.value_counts().min()}-{val_dataset.setid.value_counts().max()} \\t{val_dataset.count(axis=1).size/dataset.count(axis=1).size:.5f}\")\n",
    "print(f\"> test: \\t{test_dataset.count(axis=1).size}  \\t{test_dataset.setid.value_counts().min()}-{test_dataset.setid.value_counts().max()} \\t{test_dataset.count(axis=1).size/dataset.count(axis=1).size:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path\n",
      "False    287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "path\n",
      "False    287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "path\n",
      "False    87\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((train_dataset.path.isin(test_dataset.path) == True).value_counts(), end='\\n\\n')\n",
    "print((train_dataset.path.isin(val_dataset.path) == True).value_counts(), end='\\n\\n')\n",
    "print((val_dataset.path.isin(test_dataset.path) == True).value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save / load datasets slices (train, val, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv(os.path.join(DATASETS_INFO_PATHS.originals, 'train_dataset.csv'), index=False)\n",
    "val_dataset.to_csv(os.path.join(DATASETS_INFO_PATHS.originals, 'val_dataset.csv'), index=False)\n",
    "test_dataset.to_csv(os.path.join(DATASETS_INFO_PATHS.originals, 'test_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(os.path.join(DATASETS_INFO_PATHS.originals, 'train_dataset.csv'))\n",
    "val_dataset = pd.read_csv(os.path.join(DATASETS_INFO_PATHS.originals, 'val_dataset.csv'))\n",
    "test_dataset = pd.read_csv(os.path.join(DATASETS_INFO_PATHS.originals, 'test_dataset.csv'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
